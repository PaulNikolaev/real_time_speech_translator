# Приложение для перевода речи: Русский -> Английский/Французский

Приложение для перевода речи в реальном времени с русского языка на английский или французский. Записывает речь с микрофона, распознает, переводит и озвучивает результат через колонки.

## Технологии

- **Распознавание речи**: faster-whisper
- **Перевод**: NLLB-200 (Facebook)
- **Синтез речи**: Bark (Suno AI)
- **Аудио**: sounddevice, soundfile

## Требования

- Python 3.8+
- Микрофон и динамики/наушники
- (Опционально) NVIDIA GPU с CUDA для ускорения обработки

## Установка

1. **Клонируйте репозиторий** (если еще не сделали)

2. **Сначала установите PyTorch** (выберите один вариант):

   **Для CUDA 11.8** (если у вас есть NVIDIA GPU) - рекомендуется:
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```
   Это установит последнюю версию PyTorch с поддержкой CUDA 11.8 (совместимо с большинством GPU).
   
   **Для CUDA 12.1** (альтернативный вариант):
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
   ```
   
   **Для CPU** (если GPU нет):
   ```bash
   pip install torch torchvision torchaudio
   ```

3. **Затем установите остальные зависимости**:
```bash
pip install -r requirements.txt
```

3. **Создайте файл `.env`** (опционально):
   Создайте файл `.env` в корневой директории проекта для настройки параметров:
   ```env
   # Устройство для обработки (cuda или cpu, по умолчанию определяется автоматически)
   DEVICE=cuda
   
   # Частота дискретизации аудио (по умолчанию 44100 для лучшего качества)
   SAMPLE_RATE=44100
   
   # Длительность записи в секундах (по умолчанию 5)
   RECORD_DURATION=5
   
   # Папка для хранения моделей (по умолчанию "models")
   MODELS_DIR=models
   
   # Токен Hugging Face (опционально, не обязателен для публичных моделей)
   HF_TOKEN=your_token_here
   ```
   
   Все параметры опциональны - приложение будет работать со значениями по умолчанию.

## Запуск

Запустите приложение:
```bash
python main.py
```

## Использование

1. При запуске выберите целевой язык (1 - Английский, 2 - Французский)
2. Дождитесь загрузки моделей (первый запуск может занять время - модели загружаются автоматически)
3. Нажмите Enter для начала записи
4. Говорите на русском языке в течение 5 секунд
5. Дождитесь обработки:
   - Распознавание речи
   - Перевод текста
   - Синтез речи на целевом языке
   - Воспроизведение результата
6. Нажмите Enter для следующей записи или Ctrl+C для выхода

## Первый запуск

При первом запуске приложение загрузит следующие модели:
- **Whisper base** (~150 MB) - для распознавания речи
- **NLLB-200-distilled-600M** (~2.3 GB) - для перевода
- **Bark** (~1.0 GB) - для синтеза речи (полная модель для лучшего качества)

Модели будут сохранены в папке `models/` для последующего использования.

## Производительность

- **На GPU** (NVIDIA с CUDA): ~5-8 секунд обработки
- **На CPU**: ~12-20 секунд обработки

## Структура проекта

```
RealTimeSpeechTtranslator/
├── main.py              # Точка входа
├── config.py            # Конфигурация
├── requirements.txt     # Зависимости
├── audio/               # Модуль работы с аудио
├── recognition/         # Модуль распознавания речи
├── translation/         # Модуль перевода
├── synthesis/           # Модуль синтеза речи
├── core/                # Основной класс-оркестратор
└── utils/               # Утилиты (мониторинг памяти GPU)
```

## Возможные проблемы

1. **Ошибка при записи аудио**: Убедитесь, что микрофон подключен и доступен системе
2. **Ошибка при воспроизведении**: Проверьте настройки звука и подключение колонок/наушников
3. **Нехватка памяти GPU**: Если у вас GPU с <8GB VRAM, приложение будет работать медленнее. Рассмотрите использование CPU или уменьшение размера моделей.
4. **Медленная обработка на CPU**: Это нормально. Ожидайте ~12-20 секунд на обработку.

## Примечания

- Приложение работает полностью на CPU, но обработка будет медленнее
- Все модели поддерживают работу на CPU
- Временные аудиофайлы сохраняются в папке `temp_audio/`
